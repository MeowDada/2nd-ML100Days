{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def fetch_images_from_path(path):\n",
    "    lst = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if '.jpg' in file:\n",
    "                lst.append(root + file)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_path = '../data/kaggle_dogcat'\n",
    "\n",
    "train_dogs_path = dir_path + '/train/dogs/'\n",
    "train_cats_path = dir_path + '/train/cats/'\n",
    "test_images_path  = dir_path + '/test/'\n",
    "\n",
    "train_dogs = fetch_images_from_path(train_dogs_path)\n",
    "train_cats = fetch_images_from_path(train_cats_path)\n",
    "test_images  = fetch_images_from_path(test_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dogs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_dogs = len(train_dogs)\n",
    "num_train_cats = len(train_cats)\n",
    "num_test_images = len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_train_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = '../data/kaggle_dogcat/processed'\n",
    "\n",
    "image_size = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_image_to_target_path(source_list ,store_path, image_size):\n",
    "    cnt = 0\n",
    "    for file in source_list:\n",
    "        img = Image.open(file)\n",
    "        resized_img = img.resize(image_size)\n",
    "        resized_img.save(store_path + '{0}.jpg'.format(cnt))\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_image_to_target_path(train_dogs, processed_dir + '/train/dogs/', image_size)\n",
    "resize_image_to_target_path(train_cats, processed_dir + '/train/cats/', image_size)\n",
    "resize_image_to_target_path(test_images, processed_dir + '/test/', image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_dogs = fetch_images_from_path(processed_dir + '/train/dogs/')\n",
    "processed_train_cats = fetch_images_from_path(processed_dir + '/train/cats/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_image_to_target_path(dog_files, cat_files, path):\n",
    "    cnt = 0\n",
    "    for file in dog_files:\n",
    "        img = Image.open(file)\n",
    "        img.save(path + '/{0}.jpg'.format(cnt))\n",
    "        cnt += 1\n",
    "    for file in cat_files:\n",
    "        img = Image.open(file)\n",
    "        img.save(path + '/{0}.jpg'.format(cnt))\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_image_to_target_path(processed_train_dogs, processed_train_cats, processed_dir + '/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir = '../data/kaggle_dogcat/processed'\n",
    "\n",
    "image_size = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def open_images_as_numpy_array(path, nums):\n",
    "    lst = []\n",
    "    for i in range(nums):\n",
    "        fname = path + '{0}.jpg'.format(i)\n",
    "        img = Image.open(fname)\n",
    "        lst.append(np.array(img))\n",
    "    return np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = open_images_as_numpy_array(processed_dir + '/train/', 4000)\n",
    "y_train = [0]*2000 + [1]*2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "x_train = x_train.astype('float32') / 255\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=2, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "lst = []\n",
    "\n",
    "for image, label in zip(x_train, y_train):\n",
    "    lst.append((image, label))\n",
    "\n",
    "shuffle(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    image, label = lst[i]\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lst = []\n",
    "y_train_lst = []\n",
    "\n",
    "for pair in lst:\n",
    "    image, label = pair\n",
    "    x_train_lst.append(image)\n",
    "    y_train_lst.append(label)\n",
    "    \n",
    "x_train = np.array(x_train_lst)\n",
    "y_train = np.array(y_train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Class #0 = cats\n",
      "Class #1 = dogs\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "DATASET_PATH  = '../data/kaggle_dogcat/processed'\n",
    "IMAGE_SIZE    = (224, 224)\n",
    "BATCH_SIZE    = 32\n",
    "NUM_CLASSES   = 2\n",
    "FREEZE_LAYERS = 2\n",
    "NUM_EPOCHS    = 50\n",
    "\n",
    "# 模型輸出儲存的檔案\n",
    "WEIGHTS_FINAL = 'model-resnet50-final.h5'\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rotation_range=20,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   channel_shift_range=5,\n",
    "                                   horizontal_flip=True,\n",
    "                                   rescale=1/.255,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1/.255)\n",
    "valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/valid',\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  interpolation='bicubic',\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False,\n",
    "                                                  batch_size=BATCH_SIZE)\n",
    "\n",
    "for cls, idx in train_batches.class_indices.items():\n",
    "    print('Class #{} = {}'.format(idx, cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score    \n",
    "\n",
    "'''\n",
    "net = ResNet50(include_top=False, weights='imagenet', input_tensor=None,\n",
    "               input_shape=(IMAGE_SIZE[0],IMAGE_SIZE[1],3))\n",
    "x = net.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)\n",
    "'''\n",
    "from keras.models import Sequential\n",
    "\n",
    "vgg16_model = keras.applications.vgg16.VGG16(weights='vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)\n",
    "    \n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定凍結與要進行訓練的網路層\n",
    "'''\n",
    "for layer in net_final.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "net_final.layers[-1].trainable = True\n",
    "net_final.compile(optimizer=Adam(lr=1e-5),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "'''\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(Adam(lr=.00002122), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 01:23:26.703009  7656 deprecation.py:323] From C:\\Users\\Scherzando\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 44s 438ms/step - loss: 2.4850 - acc: 0.5962 - val_loss: 1.4533 - val_acc: 0.7075\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 41s 407ms/step - loss: 1.1315 - acc: 0.7613 - val_loss: 0.8904 - val_acc: 0.8237\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 39s 389ms/step - loss: 0.7683 - acc: 0.8238 - val_loss: 0.7215 - val_acc: 0.8550\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 38s 379ms/step - loss: 0.6436 - acc: 0.8491 - val_loss: 0.6098 - val_acc: 0.8725\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 38s 379ms/step - loss: 0.5517 - acc: 0.8650 - val_loss: 0.5478 - val_acc: 0.8875\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 0.5122 - acc: 0.8734 - val_loss: 0.4941 - val_acc: 0.9038\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 0.4374 - acc: 0.8869 - val_loss: 0.4600 - val_acc: 0.9075\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 0.3647 - acc: 0.9025 - val_loss: 0.4299 - val_acc: 0.9137\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 0.3805 - acc: 0.9022 - val_loss: 0.3973 - val_acc: 0.9163\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 0.3522 - acc: 0.9034 - val_loss: 0.3848 - val_acc: 0.9225\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 0.3452 - acc: 0.9119 - val_loss: 0.3675 - val_acc: 0.9237\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.3461 - acc: 0.9097 - val_loss: 0.3640 - val_acc: 0.9275\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.2943 - acc: 0.9197 - val_loss: 0.3627 - val_acc: 0.9275\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 0.2827 - acc: 0.9244 - val_loss: 0.3430 - val_acc: 0.9263\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.2755 - acc: 0.9216 - val_loss: 0.3339 - val_acc: 0.9250\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 0.2917 - acc: 0.9231 - val_loss: 0.3297 - val_acc: 0.9263\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 0.2824 - acc: 0.9237 - val_loss: 0.3221 - val_acc: 0.9300\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 0.2433 - acc: 0.9300 - val_loss: 0.3210 - val_acc: 0.9325\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 38s 378ms/step - loss: 0.2749 - acc: 0.9281 - val_loss: 0.3005 - val_acc: 0.9313\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 0.2483 - acc: 0.9300 - val_loss: 0.3136 - val_acc: 0.9313\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.2402 - acc: 0.9303 - val_loss: 0.2994 - val_acc: 0.9337\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.2351 - acc: 0.9344 - val_loss: 0.2992 - val_acc: 0.9325\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.2245 - acc: 0.9369 - val_loss: 0.2915 - val_acc: 0.9350\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 0.2321 - acc: 0.9356 - val_loss: 0.2841 - val_acc: 0.9363\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 0.2334 - acc: 0.9347 - val_loss: 0.2929 - val_acc: 0.9337\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.2084 - acc: 0.9378 - val_loss: 0.2830 - val_acc: 0.9350\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 0.2072 - acc: 0.9394 - val_loss: 0.2854 - val_acc: 0.9363\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.1858 - acc: 0.9450 - val_loss: 0.2785 - val_acc: 0.9350\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 0.1921 - acc: 0.9437 - val_loss: 0.2747 - val_acc: 0.9350\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.1975 - acc: 0.9441 - val_loss: 0.2630 - val_acc: 0.9413\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.2210 - acc: 0.9375 - val_loss: 0.2695 - val_acc: 0.9363\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.2042 - acc: 0.9384 - val_loss: 0.2615 - val_acc: 0.9413\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.1639 - acc: 0.9463 - val_loss: 0.2608 - val_acc: 0.9425\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.2002 - acc: 0.9416 - val_loss: 0.2572 - val_acc: 0.9425\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1720 - acc: 0.9441 - val_loss: 0.2602 - val_acc: 0.9413\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1706 - acc: 0.9503 - val_loss: 0.2574 - val_acc: 0.9425\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1717 - acc: 0.9459 - val_loss: 0.2696 - val_acc: 0.9387\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 0.1720 - acc: 0.9469 - val_loss: 0.2526 - val_acc: 0.9437\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1599 - acc: 0.9481 - val_loss: 0.2583 - val_acc: 0.9437\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1876 - acc: 0.9447 - val_loss: 0.2583 - val_acc: 0.9425\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 37s 375ms/step - loss: 0.1625 - acc: 0.9441 - val_loss: 0.2482 - val_acc: 0.9425\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1823 - acc: 0.9456 - val_loss: 0.2495 - val_acc: 0.9413\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1547 - acc: 0.9537 - val_loss: 0.2462 - val_acc: 0.9413\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.1463 - acc: 0.9516 - val_loss: 0.2425 - val_acc: 0.9413\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.1514 - acc: 0.9528 - val_loss: 0.2472 - val_acc: 0.9413\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1435 - acc: 0.9522 - val_loss: 0.2389 - val_acc: 0.9425\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 37s 372ms/step - loss: 0.1384 - acc: 0.9562 - val_loss: 0.2468 - val_acc: 0.9437\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1720 - acc: 0.9503 - val_loss: 0.2424 - val_acc: 0.9437\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 0.1525 - acc: 0.9531 - val_loss: 0.2481 - val_acc: 0.9425\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.1412 - acc: 0.9559 - val_loss: 0.2338 - val_acc: 0.9425\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_batches,\n",
    "                        steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "                        validation_data = valid_batches,\n",
    "                        validation_steps = valid_batches.samples // BATCH_SIZE,\n",
    "                        epochs = NUM_EPOCHS)\n",
    "\n",
    "# 儲存訓練好的模型\n",
    "model.save(WEIGHTS_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/kaggle_dogcat/processed/test\n",
      "Found 400 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "print(DATASET_PATH + '/test')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/.255)\n",
    "test_batches = test_datagen.flow_from_directory(DATASET_PATH + '/test',\n",
    "                                                target_size=IMAGE_SIZE,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False,\n",
    "                                                batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = open_images_as_numpy_array(processed_dir + '/test/test/', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_final.load_weights(WEIGHTS_FINAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict_generator(test_batches, steps=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27359673, 0.72640324],\n",
       "       [0.22123948, 0.77876055],\n",
       "       [0.37720594, 0.62279403],\n",
       "       [0.2955681 , 0.70443195],\n",
       "       [0.29024053, 0.7097595 ],\n",
       "       [0.36384672, 0.6361533 ],\n",
       "       [0.26339388, 0.7366062 ],\n",
       "       [0.32249004, 0.67750996],\n",
       "       [0.31364888, 0.6863511 ],\n",
       "       [0.3923276 , 0.60767233]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['ID','Predicted'])\n",
    "    col_id = 0\n",
    "    for col in y_test:\n",
    "        val = col[0]\n",
    "        if val < 0.1:\n",
    "            val = 0.0\n",
    "        writer.writerow([str(col_id).zfill(3), val])\n",
    "        col_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"final.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
